{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_id = 'slither-AE-LSTM-final-n' # base case, LSTM 512, 512\n",
    "# load_id = 'test_universe-AE-LSTM-C5' + '-ext' # with attentional transition, 512, 512, 4\n",
    "# load_id = 'test_universe-AE-LSTM-C5' + '-large' # with larger state, 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code referenced from https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc \n",
    "try:\n",
    "    from StringIO import StringIO  # Python 2.7\n",
    "except ImportError:\n",
    "    from io import BytesIO         # Python 3.00\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    \n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "\n",
    "    def scalar_summary(self, tag, value, step):\n",
    "        \"\"\"Log a scalar variable.\"\"\"\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "\n",
    "    def image_summary(self, tag, images, step):\n",
    "        \"\"\"Log a list of images.\"\"\"\n",
    "\n",
    "        img_summaries = []\n",
    "        for i, img in enumerate(images):\n",
    "            # Write the image to a string\n",
    "            try:\n",
    "                s = StringIO()\n",
    "            except:\n",
    "                s = BytesIO()\n",
    "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
    "\n",
    "            # Create an Image object\n",
    "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
    "                                       height=img.shape[0],\n",
    "                                       width=img.shape[1])\n",
    "            # Create a Summary value\n",
    "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=img_summaries)\n",
    "        self.writer.add_summary(summary, step)\n",
    "        \n",
    "    def pltfig_summary(self, tag, images, step):\n",
    "        \"\"\"Log a list of images.\"\"\"\n",
    "\n",
    "        img_summaries = []\n",
    "        for i, img in enumerate(images):\n",
    "            # Write the image to a string\n",
    "            try:\n",
    "                s = StringIO()\n",
    "            except:\n",
    "                s = BytesIO()\n",
    "            img.savefig(s, format=\"png\")\n",
    "\n",
    "            # Create an Image object\n",
    "            shape = (img.get_dpi() * img.get_size_inches()).astype(int) # w, h\n",
    "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
    "                                       height=shape[1],\n",
    "                                       width=shape[0])\n",
    "            # Create a Summary value\n",
    "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=img_summaries)\n",
    "        self.writer.add_summary(summary, step)\n",
    "        self.writer.flush()\n",
    "        \n",
    "    def histo_summary(self, tag, values, step, bins=1000):\n",
    "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
    "\n",
    "        # Create a histogram using numpy\n",
    "        counts, bin_edges = np.histogram(values, bins=bins)\n",
    "\n",
    "        # Fill the fields of the histogram proto\n",
    "        hist = tf.HistogramProto()\n",
    "        hist.min = float(np.min(values))\n",
    "        hist.max = float(np.max(values))\n",
    "        hist.num = int(np.prod(values.shape))\n",
    "        hist.sum = float(np.sum(values))\n",
    "        hist.sum_squares = float(np.sum(values**2))\n",
    "\n",
    "        # Drop the start of the first bin\n",
    "        bin_edges = bin_edges[1:]\n",
    "\n",
    "        # Add bin edges and counts\n",
    "        for edge in bin_edges:\n",
    "            hist.bucket_limit.append(edge)\n",
    "        for c in counts:\n",
    "            hist.bucket.append(c)\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "log_dir = '/tmp/tb/' + nb_id\n",
    "! rm -r $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib as mpl\n",
    "plt = mpl.pyplot\n",
    "# mpl.pylab.rcParams['figure.figsize'] = (12, 9)\n",
    "\n",
    "import numpy as np\n",
    "import torch as tch\n",
    "F = tch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pytorch auxiliar functions\n",
    "def np2var(input):\n",
    "    output = tch.autograd.Variable(tch.from_numpy(input))\n",
    "    if tch.cuda.is_available():\n",
    "        output = output.cuda()\n",
    "    return output\n",
    "\n",
    "# tanh2sigmoid = lambda x: (x + 1) / 2\n",
    "\n",
    "def postprocess(tch_img):\n",
    "    return (tch_img * 255).byte().data.cpu().numpy().squeeze()\n",
    "\n",
    "# screen slicing00\n",
    "top = 86\n",
    "left = 20 + 100\n",
    "height = 300\n",
    "width = 500 - 200\n",
    "gamescreen_slice = (slice(top,  top + height), slice(left, left + width))\n",
    "game_center = (top + height // 2, left + width // 2) # y, x\n",
    "game_center = game_center[::-1]\n",
    "\n",
    "# average pooling for downscaling\n",
    "s = downscale_size = 2\n",
    "pool2d_downscale = tch.nn.AvgPool2d((s, s), stride=(s, s))\n",
    "downscale_n = 1\n",
    "downscale = downscale_size ** downscale_n\n",
    "dummy_img = np.zeros((height // downscale, width // downscale, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CNN_encoder(tch.nn.Module):\n",
    "    def __init__(self, n_convs=5, out_ch=128, act=F.selu):\n",
    "        \n",
    "        super(CNN_encoder, self).__init__()\n",
    "        \n",
    "        self.n_convs = n_convs\n",
    "        self.kernel_size = (4, 4)\n",
    "        self.out_ch = out_ch\n",
    "        self.act = act\n",
    "        \n",
    "        self.conv_layers = tch.nn.ModuleList()\n",
    "        self.conv_layers.append(tch.nn.Conv2d(1, 16, self.kernel_size, stride=(2, 2), padding=(2, 2)))\n",
    "        self.conv_layers.append(tch.nn.Conv2d(16, 16, self.kernel_size, stride=(2, 2), padding=(1, 1)))\n",
    "        self.conv_layers.append(tch.nn.Conv2d(16, 32, self.kernel_size, stride=(2, 2), padding=(2, 2)))\n",
    "        self.conv_layers.append(tch.nn.Conv2d(32, 64, self.kernel_size, stride=(2, 2), padding=(1, 1)))\n",
    "        self.conv_layers.append(tch.nn.Conv2d(64, 128, self.kernel_size, stride=(2, 2), padding=(1, 1)))\n",
    "        self.conv_layers.append(tch.nn.Conv2d(128, 512, (5, 5), stride=(1, 1), padding=(0, 0)))\n",
    "            \n",
    "        self.last_conv_unrolled_size = 512\n",
    "        self.fc_sizes = []\n",
    "        self.fc_layers = tch.nn.ModuleList()\n",
    "        in_size = self.last_conv_unrolled_size\n",
    "        for out_size in self.fc_sizes:\n",
    "            self.fc_layers.append(tch.nn.Linear(in_size, out_size))\n",
    "            in_size = out_size\n",
    "            \n",
    "        self.conv_sizes = []\n",
    "            \n",
    "    def forward(self, input):\n",
    "        \n",
    "        self.conv_sizes = []\n",
    "\n",
    "        output = input\n",
    "        for layer in list(self.conv_layers):\n",
    "            self.conv_sizes.append(tuple(output.size()))\n",
    "            output = self.act(layer(output))\n",
    "        self.conv_sizes.append(tuple(output.size()))\n",
    "        \n",
    "        output = output.view(-1, self.last_conv_unrolled_size)\n",
    "        \n",
    "        for layer in self.fc_layers:\n",
    "            output = self.act(layer(output))\n",
    "        \n",
    "        return output\n",
    "\n",
    "encoder = CNN_encoder()\n",
    "\n",
    "# for param in encoder.parameters():\n",
    "#     n = np.prod(list(param.size())[-3:]) # valid for 2D convolutions\n",
    "#     stdv = 2. / math.sqrt(n)\n",
    "#     param.data.uniform_(-stdv, stdv)\n",
    "\n",
    "if tch.cuda.is_available():\n",
    "    encoder = encoder.cuda()\n",
    "\n",
    "dummy_img_T = dummy_img.transpose(2, 0, 1)\n",
    "dummy_img_T = np2var(dummy_img_T).float().unsqueeze(0)\n",
    "_ = encoder(dummy_img_T)\n",
    "\n",
    "encoder.conv_sizes\n",
    "\n",
    "class CNN_decoder(tch.nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        \n",
    "        super(CNN_decoder, self).__init__()\n",
    "        \n",
    "        self.act = encoder.act\n",
    "        \n",
    "        self.input_size = encoder.fc_sizes[-1] if len(encoder.fc_sizes) > 0 else None\n",
    "        self.fc_sizes = (encoder.fc_sizes[-2::-1] + [encoder.last_conv_unrolled_size] \n",
    "                         if len(encoder.fc_sizes) > 0 else [])\n",
    "        \n",
    "        self.last_conv_shape = (-1, ) + encoder.conv_sizes[-1][1:]\n",
    "        \n",
    "        self.fc_layers = tch.nn.ModuleList()\n",
    "\n",
    "        in_size = self.input_size\n",
    "        for out_size in self.fc_sizes:\n",
    "            self.fc_layers.append(tch.nn.Linear(in_size, out_size))\n",
    "            in_size = out_size\n",
    "            \n",
    "            \n",
    "        self.convtrans_layers = tch.nn.ModuleList()\n",
    "        in_ch = encoder.conv_sizes[-1][1]\n",
    "        for output_shape, encode_layer in zip(encoder.conv_sizes[-2::-1], tuple(encoder.conv_layers)[::-1]):\n",
    "            out_ch = output_shape[1]\n",
    "            self.convtrans_layers.append(tch.nn.ConvTranspose2d(in_ch, out_ch,\n",
    "                                                                encode_layer.kernel_size,\n",
    "                                                                encode_layer.stride,\n",
    "                                                                encode_layer.padding))\n",
    "            in_ch = out_ch\n",
    "            \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = input\n",
    "        for layer in self.fc_layers:\n",
    "            output = self.act(layer(output))\n",
    "            \n",
    "        output = output.view(*self.last_conv_shape)\n",
    "        \n",
    "        for layer in list(self.convtrans_layers)[:-1]:\n",
    "            output = self.act(layer(output))\n",
    "        output = tch.sigmoid(self.convtrans_layers[-1](output))\n",
    "        \n",
    "        return output\n",
    "        \n",
    "\n",
    "decoder = CNN_decoder(encoder)\n",
    "\n",
    "# for param in decoder.parameters():\n",
    "#     n = 1 if len(param.size()) == 1 else param.size()[0]\n",
    "#     n *= np.prod(list(param.size())[-2:]) # valid for 2D convolutions\n",
    "#     stdv = 2. / math.sqrt(n)\n",
    "#     param.data.uniform_(-stdv, stdv)\n",
    "\n",
    "if tch.cuda.is_available():\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class customLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_variants):\n",
    "        super(customLSTMCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_variants = num_variants\n",
    "        \n",
    "        self.ih = nn.Linear(self.input_size, 4 * self.hidden_size * self.num_variants)\n",
    "        self.hh = nn.Linear(self.hidden_size, 4 * self.hidden_size * self.num_variants)\n",
    "        \n",
    "        self.hhh = nn.Linear(self.hidden_size, self.num_variants)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        hx, cx = hidden\n",
    "        \n",
    "        gates = self.ih(input) + self.hh(hx)\n",
    "        \n",
    "        gates_weights = F.softmax(self.hhh(cx))\n",
    "        gates = gates.view(-1, 4 * self.hidden_size, self.num_variants)\n",
    "        gates = torch.matmul(gates, gates_weights.squeeze())        \n",
    "        \n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "        \n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "        \n",
    "        cy = (forgetgate * cx) + (ingate * cellgate)\n",
    "        hy = outgate * F.tanh(cy)\n",
    "\n",
    "        return hy, cy\n",
    "\n",
    "class LSTM_predictor(tch.nn.Module):\n",
    "    \n",
    "    def __init__(self, size, hidden_size):\n",
    "        \n",
    "        super(LSTM_predictor, self).__init__()\n",
    "        \n",
    "        self.cell = tch.nn.LSTMCell(size, hidden_size)\n",
    "        \n",
    "        self.output_layer = tch.nn.Linear(hidden_size, size)\n",
    "        \n",
    "        self.act = encoder.act\n",
    "        \n",
    "    def forward(self, hidden, input):\n",
    "               \n",
    "        hidden = self.cell(input, hidden)\n",
    "        \n",
    "        output = self.act(self.output_layer(hidden[0]))\n",
    "        \n",
    "        return hidden, output\n",
    "        \n",
    "    def zero_hidden(self):\n",
    "        \n",
    "        hidden = (tch.autograd.Variable(tch.zeros(1, self.cell.hidden_size)),\n",
    "                  tch.autograd.Variable(tch.zeros(1, self.cell.hidden_size)))\n",
    "        \n",
    "        if tch.cuda.is_available():\n",
    "            hidden = tuple(h.cuda() for h in hidden)\n",
    "            \n",
    "        return hidden # h_0, c_0\n",
    "    \n",
    "predictor = LSTM_predictor(512, 512)\n",
    "\n",
    "if tch.cuda.is_available():\n",
    "    predictor = predictor.cuda()\n",
    "    \n",
    "class dummy_module(tch.nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, predictor):\n",
    "        super(dummy_module, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.predictor = predictor\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "dummy = dummy_module(encoder, decoder, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_load = tch.load(load_id + 'dummy.pkl')\n",
    "for module, module_load in zip((encoder, decoder, predictor), tuple(dummy_load.children())):\n",
    "    for param, param_load in zip(module.parameters(), module_load.parameters()):\n",
    "        param.data = param_load.data\n",
    "\n",
    "# history = pickle.load(open(load_id, \"rb\"))\n",
    "# encoder_load = tch.load(load_id + 'encoder')\n",
    "# decoder_load = tch.load(load_id + 'decoder')\n",
    "# predictor_load = tch.load(load_id + 'predictor')\n",
    "\n",
    "# for module, module_load in zip((encoder, decoder, predictor), (encoder_load, decoder_load, predictor_load)):\n",
    "#     for param, param_load in zip(module.parameters(), module_load.parameters()):\n",
    "#         param.data = param_load.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "assert decoder(encoder(dummy_img_T)).size() == dummy_img_T.size()\n",
    "assert decoder(predictor(predictor.zero_hidden(), encoder(dummy_img_T))[1]).size() == dummy_img_T.size()\n",
    "# fig.canvas.draw()\n",
    "end = time.time()\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "assert decoder(encoder(dummy_img_T)).size() == dummy_img_T.size()\n",
    "assert decoder(predictor(predictor.zero_hidden(), encoder(dummy_img_T))[1]).size() == dummy_img_T.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = tch.nn.MSELoss()\n",
    "bce_criterion = lambda x, y: tch.nn.BCELoss(size_average=True)(x, y)\n",
    "\n",
    "ae_params = tuple(encoder.parameters()) + tuple(decoder.parameters())\n",
    "rnn_params = tuple(predictor.parameters())\n",
    "optimizer = tch.optim.SGD(ae_params + rnn_params, lr=1e-1, momentum=0.9)\n",
    "# ae_optimizer = tch.optim.SGD(ae_params, lr=1e-2, momentum=0.99)\n",
    "# rnn_optimizer = tch.optim.SGD(rnn_params, lr=1e-2, momentum=0.99)\n",
    "# ae_optimizer = tch.optim.Adam(ae_params)\n",
    "# rnn_optimizer = tch.optim.Adam(rnn_params)\n",
    "# pred_optimizer = tch.optim.Adam(rnn_params, lr=1e-3)\n",
    "# optimizer = tch.optim.Adam(ae_params, lr=1e-4, betas=(0.99, 0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step_counter = 0 + pickle.load(open(load_id + 'tsc.pickle', 'rb'))\n",
    "\n",
    "plot_every = 1\n",
    "\n",
    "buffer_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_id = 'slither-AE-LSTM-final-n'\n",
    "\n",
    "log_dir = './tb_final/' + nb_id\n",
    "# ! rm -r $log_dir\n",
    "\n",
    "logger = Logger(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guille/anaconda3/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type CNN_encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/guille/anaconda3/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type CNN_decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/guille/anaconda3/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type LSTM_predictor. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/guille/anaconda3/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type dummy_module. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4e77bf12b6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# encoding and prediction gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mtrue_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0;31m# prediction and decoding gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/guille/anaconda3/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/guille/anaconda3/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "true_total_loss_ae = 0\n",
    "true_total_loss_pred = 0\n",
    "\n",
    "train_steps = 0\n",
    "\n",
    "train_queue = deque(maxlen=buffer_size)\n",
    "\n",
    "hidden = predictor.zero_hidden()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    with open('./game_dataset/' + random.choice(os.listdir('./game_dataset')), 'rb') as gamescreen_file:\n",
    "              \n",
    "        gamescreen_list = pickle.load(gamescreen_file)\n",
    "        \n",
    "        for gamescreen, _ in gamescreen_list:\n",
    "            \n",
    "            is_last = gamescreen is gamescreen_list[-1][0]\n",
    "            \n",
    "            gamescreen = np2var(gamescreen).float() / 255\n",
    "            gamescreen = gamescreen.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            train_queue.append(gamescreen)\n",
    "\n",
    "            if len(train_queue) == buffer_size or (is_last and len(train_queue) > 1):\n",
    "                train_steps += 1\n",
    "              \n",
    "                # encode\n",
    "                train_batch = tch.cat(train_queue, dim=0)\n",
    "                coded_batch = encoder(train_batch)\n",
    "                # autoencode\n",
    "                decoded_batch = decoder(coded_batch)\n",
    "                loss_ae = bce_criterion(decoded_batch, train_batch.detach()) * (len(train_queue) / buffer_size)\n",
    "              \n",
    "                # predict\n",
    "                pred_list = []\n",
    "                for code in coded_batch[:-1]:\n",
    "                    code = code.unsqueeze(0)\n",
    "                    # predict\n",
    "                    hidden, pred_code = predictor(hidden, code.detach())\n",
    "                    pred_list.append(pred_code)\n",
    "\n",
    "                hidden = tuple(h.detach() for h in hidden)\n",
    "            \n",
    "                pred_coded_batch = tch.cat(pred_list, dim=0)\n",
    "                loss_pred = criterion(pred_coded_batch, coded_batch[1:].detach()) * (len(train_queue) / buffer_size)\n",
    "                \n",
    "                true_loss = loss_ae + loss_pred\n",
    "                \n",
    "                #### here only for comparison with other runs\n",
    "                pred_decoded_batch = decoder(pred_coded_batch)\n",
    "                # normalizing for shorter `train_queue`s\n",
    "                loss = bce_criterion(pred_decoded_batch.detach(), train_batch[1:].detach()) * (len(train_queue) / buffer_size)\n",
    "                train_queue.clear()\n",
    "                train_queue.append(gamescreen) # add last gamescreen as the first of the next batch\n",
    "              \n",
    "                # take step\n",
    "                step_counter += 1\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                # encoding and prediction gradient\n",
    "                true_loss.backward()\n",
    "                # prediction and decoding gradient\n",
    "                optimizer.step()\n",
    "\n",
    "                if step_counter % 32 == 1:\n",
    "                    name = 'encoder/ratio_'\n",
    "                    for i, param in enumerate(encoder.parameters()):\n",
    "                        logger.scalar_summary(name + str(i) + str(tuple(param.size())),\n",
    "                                              param.grad.data.norm() / param.data.norm(), step_counter)\n",
    "                    name = 'decoder/ratio_'\n",
    "                    for i, param in enumerate(decoder.parameters()):\n",
    "                        logger.scalar_summary(name + str(i) + str(tuple(param.size())),\n",
    "                                              param.grad.data.norm() / param.data.norm(), step_counter)\n",
    "                    name = 'rnn/ratio_'\n",
    "                    for i, param in enumerate(rnn_params):\n",
    "                        logger.scalar_summary(name + str(i) + str(tuple(param.size())),\n",
    "                                              param.grad.data.norm() / param.data.norm(), step_counter)\n",
    "                # accumulate\n",
    "                total_loss += loss.data[0]\n",
    "                true_total_loss_ae += loss_ae.data[0]\n",
    "                true_total_loss_pred += loss_pred.data[0]\n",
    "                \n",
    "#                 # autoencoding\n",
    "#                 decoded_gamescreen = decoded_batch[-1:]\n",
    "#                 decoded_pred_gamescreen = decoder(pred_batch_coded[-1:])\n",
    "\n",
    "#                 #displaying\n",
    "#                 gamescreen = postprocess(gamescreen)\n",
    "#                 decoded_gamescreen = postprocess(decoded_gamescreen)\n",
    "#                 decoded_pred_gamescreen = postprocess(decoded_pred_gamescreen)\n",
    "#                 imgs[0].set_data(gamescreen)\n",
    "#                 imgs[1].set_data(decoded_gamescreen)\n",
    "#                 imgs[2].set_data(decoded_pred_gamescreen)\n",
    "#                 fig.canvas.draw()\n",
    "\n",
    "        if train_steps > 0:\n",
    "            logger.scalar_summary('loss', total_loss / train_steps, step_counter)\n",
    "            logger.scalar_summary('true_loss_naive/ae', true_total_loss_ae / train_steps, step_counter)\n",
    "            logger.scalar_summary('true_loss_naive/pred', true_total_loss_pred / train_steps, step_counter)\n",
    "\n",
    "        total_loss = 0\n",
    "        true_total_loss_ae = 0\n",
    "        true_total_loss_pred = 0\n",
    "        train_steps = 0\n",
    "\n",
    "        hidden = predictor.zero_hidden()\n",
    "        train_queue.clear()\n",
    "\n",
    "        tch.save(encoder, nb_id + 'encoder.pkl')\n",
    "        tch.save(decoder, nb_id + 'decoder.pkl')\n",
    "        tch.save(predictor, nb_id + 'predictor.pkl')\n",
    "        tch.save(dummy, nb_id + 'dummy.pkl')\n",
    "        pickle.dump(step_counter, open(load_id + 'tsc.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
